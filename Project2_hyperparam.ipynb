{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re # Used for the conversion of \"r##_c##\" in only the numbers --> TODO: check where it comes from\n",
    "from IPython.display import display\n",
    "from helpers import *\n",
    "from play_with_data import *\n",
    "from pre_processing import *\n",
    "from matrix_factorization import *\n",
    "from cross_validation import *\n",
    "from apply_classifiers import *\n",
    "from trainings_submissions import *\n",
    "from regressions_models import *\n",
    "import scipy.sparse as sp # In order to use sparse \n",
    "# Predictors imported in performance order (best to worst, according to http://surpriselib.com/)\n",
    "from surprise import SVDpp\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import SlopeOne\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import NMF\n",
    "from surprise import CoClustering\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithZScore # not scored --> to be tested quickly\n",
    "from surprise import dataset\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "from surprise import GridSearch\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "\n",
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******** Creation of a sparse matrix of the data **********\n",
    "ratings = load_data('./data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_data('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********** Formating the data correctly for Surprise + Cross Validation *****\n",
    "ratings_surpr = formating_data_surprise(ratings) # Call a method that will transform the ratings in the right format\n",
    "ratings_surpr.split(n_folds=3) # Will create the 3 folds for cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Define: algo, dataset (trainset ##############\n",
    "ratings_hyper = formating_data_surprise(ratings)\n",
    "#trainset_hyper = ratings_hyper.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_hyper.split(n_folds=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters of SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_factors_pp = np.linspace(10,30,3)\n",
    "list_lr_all_pp = np.logspace(-3.5,-2,3)\n",
    "list_reg_all_pp = np.logspace(-3,-1.5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_factors_pp = 0\n",
    "best_lr_all_pp = 0\n",
    "best_reg_all_pp = 0\n",
    "best_rmse_pp = 1000\n",
    "\n",
    "for n_factors in list_n_factors_pp:\n",
    "    for lr_all in list_lr_all_pp:\n",
    "        for reg_all in list_reg_all_pp:\n",
    "            n_factors = int(n_factors)\n",
    "            print(n_factors,lr_all,reg_all)\n",
    "\n",
    "            algorithm_bsl = SVDpp(n_factors=n_factors,lr_all=lr_all,reg_all=reg_all)\n",
    "\n",
    "\n",
    "            for trainset1, testset1 in ratings_hyper.folds():\n",
    "\n",
    "                # train and test algorithm.\n",
    "                algorithm_bsl.train(trainset1)\n",
    "                predictions1 = algorithm_bsl.test(testset1)\n",
    "\n",
    "                # Compute and print Root Mean Squared Error\n",
    "                rmse = accuracy.rmse(predictions1, verbose=True)\n",
    "                break\n",
    "            if rmse < best_rmse_svd:\n",
    "                print(\"Improvement!\")\n",
    "                best_n_factors_pp = n_factors\n",
    "                best_lr_all_pp = lr_all\n",
    "                best_reg_all_pp = reg_all\n",
    "                best_rmse_pp = rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_n_factors_pp,best_lr_all_pp,best_reg_all_pp,best_rmse_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters of NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_factors_nmf = np.linspace(30,40,3)\n",
    "list_reg_pu = np.logspace(-1.5,-1,3)\n",
    "list_reg_qi = np.logspace(-1,-0.5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_factors_nmf = 0\n",
    "best_reg_pu = 0\n",
    "best_reg_qi = 0\n",
    "best_rmse_nmf = 1000\n",
    "\n",
    "for n_factors in list_n_factors_nmf:\n",
    "    for reg_pu in list_reg_pu:\n",
    "        for reg_qi in list_reg_qi:\n",
    "            n_factors = int(n_factors)\n",
    "            print(n_factors,reg_pu,reg_qi)\n",
    "\n",
    "            algorithm_bsl = NMF(n_factors=n_factors,reg_pu=reg_pu,reg_qi=reg_qi)\n",
    "\n",
    "\n",
    "            for trainset1, testset1 in ratings_hyper.folds():\n",
    "\n",
    "                # train and test algorithm.\n",
    "                algorithm_bsl.train(trainset1)\n",
    "                predictions1 = algorithm_bsl.test(testset1)\n",
    "\n",
    "                # Compute and print Root Mean Squared Error\n",
    "                rmse = accuracy.rmse(predictions1, verbose=True)\n",
    "                break\n",
    "            if rmse < best_rmse_nmf:\n",
    "                print(\"Improvement!\")\n",
    "                best_n_factors_nmf = n_factors\n",
    "                best_reg_pu = reg_pu\n",
    "                best_reg_qi = reg_qi\n",
    "                best_rmse_nmf = rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_n_factors_nmf,best_reg_pu,best_reg_qi,best_rmse_nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35 0.0316227766017 0.316227766017 1.00321306113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters of BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaselineOnly(bsl_options={'method': 'als', 'reg_u': 14.4, 'reg_i': 0.3})\n",
    "\n",
    "# Comparer avec\n",
    "# BaselineOnly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters of KNNWithZScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNWithZScore(k=100, min_k=7, sim_options={'name':'pearson_baseline','user_based':False,'shrinkage':500})\n",
    "\n",
    "# Comparer avec\n",
    "# KNNWithZScore(sim_options={'user_based':False})\n",
    "# KNNWithZScore(k=100, min_k=7,sim_options={'user_based':False})\n",
    "\n",
    "# et Ã©ventuellement, mais moins important\n",
    "# KNNWithZScore(sim_options={'name':'pearson_baseline','user_based':False,'shrinkage':500})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters of KNNBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNBaseline(k=96, min_k=8,sim_options={'name': 'pearson_baseline','user_based': False,'shrinkage': 500},bsl_options={'method': 'als','reg_u': 14.4,'reg_i': 0.3})\n",
    "\n",
    "# Comparer avec\n",
    "# KNNBaseline()\n",
    "# KNNBaseline(k=96, min_k=8)\n",
    "# KNNBaseline(k=96, min_k=8,sim_options={'user_based':False},bsl_options={'method': 'als','reg_u': 14.4,'reg_i': 0.3})\n",
    "# KNNBaseline(k=96, min_k=8,sim_options={'name': 'pearson_baseline','user_based': False,'shrinkage': 500})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters of SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD(n_factors=100,lr_all=0.001,reg_all=0.0316227766017)\n",
    "# SVD(n_factors=100,lr_all=0.001,reg_all=10**(-1.5))\n",
    "\n",
    "# Comparer avec \n",
    "# SVD()\n",
    "\n",
    "# SVD(n_factors=100,lr_all=0.001,reg_all=0.0316227766017)\n",
    "# SVD(n_factors=100,lr_all=0.001,reg_all=10**(-1.5))\n",
    "\n",
    "# Comparer avec \n",
    "# SVD()\n",
    "\n",
    "algos = [SVD(n_factors=100,lr_all=0.001,reg_all=0.0316227766017),SVD(n_factors=100,lr_all=0.001,reg_all=10**(-1.5))\\\n",
    "        ,SVD()]\n",
    "perf = {}\n",
    "algo_str = ['SVD1','SVD2','SVD3']  \n",
    "\n",
    "for i,algo in enumerate(algos): # Loop over the algorithms \n",
    "    # Evaluate performances of \"Surprise\" algorithm on the dataset\n",
    "    perf[algo_str[i]] = evaluate(algo, ratings_surpr, measures=['RMSE']) # Evaluate the performance of each algo by cross validation \n",
    "    print_perf(perf[algo_str[i]]) # Print the performance for each algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters of SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A terminer encore, cf optimisation chez Stefan\n",
    "# SVDpp(n_factors=n_factors,lr_all=lr_all,reg_all=reg_all)\n",
    "\n",
    "# Comparer avec \n",
    "# SVDpp()\n",
    "\n",
    "\n",
    "algos = [SVDpp(n_factors=12,lr_all=0.001,reg_all=0.000501187233627),SVDpp(n_factors=10,lr_all=0.00177827941004,reg_all=0.001)\\\n",
    "        ,SVDpp()]\n",
    "perf = {}\n",
    "algo_str = ['SVDpp1','SVDpp2','SVDpp3']  \n",
    "\n",
    "for i,algo in enumerate(algos): # Loop over the algorithms \n",
    "    # Evaluate performances of \"Surprise\" algorithm on the dataset\n",
    "    perf[algo_str[i]] = evaluate(algo, ratings_surpr, measures=['RMSE']) # Evaluate the performance of each algo by cross validation \n",
    "    print_perf(perf[algo_str[i]]) # Print the performance for each algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters of NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF(n_factors=35,reg_pu=0.0316227766017,reg_qi=0.316227766017)\n",
    "# NMF(n_factors=35,reg_pu=10**(-1.5),reg_qi=10**(-0.5))\n",
    "\n",
    "# Comparer avec \n",
    "# NMF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
