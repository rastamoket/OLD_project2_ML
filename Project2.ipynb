{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re # Used for the conversion of \"r##_c##\" in only the numbers --> TODO: check where it comes from\n",
    "from helpers import *\n",
    "from play_with_data import *\n",
    "from pre_processing import *\n",
    "from matrix_factorization import *\n",
    "from cross_validation import *\n",
    "import scipy.sparse as sp # In order to use sparse \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done before the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********* Load the given data **********\n",
    "r_c, x = load_data_old('./data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********* Creation of a matrix of the data ********\n",
    "nUser = 10000\n",
    "nItem = 1000\n",
    "data = np.zeros([nUser, nItem]) # These numbers were given\n",
    "\n",
    "for ind, i in enumerate(r_c): # Loop over all the ID \n",
    "    data[int(re.findall('\\d+', i)[0])-1, int(re.findall('\\d+', i)[1])-1] = x[ind] # Use the information in the ID (row, col) to create the matrix\n",
    "\n",
    "print(data[:10,:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r_c[:10],'\\n',x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "a = []\n",
    "for i in range(df.shape[0]):\n",
    "    a.append(len(np.where(df.loc[i] != 0)[0]))\n",
    "#print(a)\n",
    "#print(len(a))\n",
    "print(np.std(a))\n",
    "print(np.mean(a))\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** Data preview ************\n",
    "# Check if there is any missed data \n",
    "# It was told us that we have the data from 10'000 users for 1000 films, but we don't have all these data\n",
    "info_general(nUser, nItem, x, data)\n",
    "print('\\n')\n",
    "info_ratings(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this barplot, we can see that ratings are not distributed in an uniform way, this may suggest that there is a bias in the rating matrix that has to be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done after the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******** Creation of a sparse matrix of the data **********\n",
    "ratings = load_data('./data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create data as required by surprise ####\n",
    "\n",
    "movies, users, ratings_nnz = sp.find(ratings.T)\n",
    "IDs_dict = {'movies ID': movies+1,\n",
    "            'ratings': ratings_nnz,\n",
    "            'users ID': users+1\n",
    "           }\n",
    "\n",
    "ratings_representation = pd.DataFrame.from_dict(IDs_dict) # Creation of the dataframe from the dictionary\n",
    "\n",
    "dataF = ratings_representation[ratings_representation.ratings != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******* Create DataFrame with the good representation of the data **********\n",
    "users_ID = np.arange(1,ratings.shape[0]+1) # To start from 1 and finish at 1000 = 1'000 indices\n",
    "movies_ID = np.arange(1,ratings.shape[1]+1) # To start from 1 and finish at 10000 = 10'000 indices\n",
    "\n",
    "users_ID_rep = users_ID.repeat(ratings.shape[1]) # To do the repeat like that: 1 1 1 ... 1 1 1  .... 1000 ... 1000\n",
    "movies_ID_rep = np.tile(movies_ID, ratings.shape[0]) # To do the repeat like that: 1 2 3 4...10000 1 2 3 ... 10000\n",
    "\n",
    "all_ratings = ratings.todense() # In order to be able to handle this like numpy\n",
    "all_ratings = np.ravel(all_ratings) # To put in one dimension\n",
    "\n",
    "# Creation of a dictionary to create the dataframe in the correct representation\n",
    "IDs_dict = {'movies ID': movies_ID_rep,\n",
    "            'ratings': all_ratings,\n",
    "            'users ID': users_ID_rep\n",
    "           }\n",
    "\n",
    "ratings_representation = pd.DataFrame.from_dict(IDs_dict) # Creation of the dataframe from the dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***** Data preview *********\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings) # Original code is from the course, ex10 'plots.py'\n",
    "print(\"Maximum number of items per user:\\t{}\\nMinimum number of items per user:\\t{}\\n\".format(np.max(num_items_per_user), np.min(num_items_per_user)))\n",
    "print(\"Maximum number of users per item:\\t{}\\nMinimum number of users per item:\\t{}\".format(np.max(num_users_per_item), np.min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_data('./sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******* Create DataFrame with the good representation of the data **********\n",
    "test_users_ID = np.arange(1,test.shape[0]+1) # To start from 1 and finish at 1000 = 1'000 indices\n",
    "test_movies_ID = np.arange(1,test.shape[1]+1) # To start from 1 and finish at 10000 = 10'000 indices\n",
    "\n",
    "test_users_ID_rep = test_users_ID.repeat(test.shape[1]) # To do the repeat like that: 1 1 1 ... 1 1 1  .... 1000 ... 1000\n",
    "test_movies_ID_rep = np.tile(test_movies_ID, test.shape[0]) # To do the repeat like that: 1 2 3 4...10000 1 2 3 ... 10000\n",
    "\n",
    "test_all_ratings = test.todense() # In order to be able to handle this like numpy\n",
    "test_all_ratings = np.ravel(test_all_ratings) # To put in one dimension\n",
    "\n",
    "# Creation of a dictionary to create the dataframe in the correct representation\n",
    "test_IDs_dict = {'movies ID': test_movies_ID_rep,\n",
    "            'ratings': test_all_ratings,\n",
    "            'users ID': test_users_ID_rep\n",
    "           }\n",
    "\n",
    "test_ratings_representation = pd.DataFrame.from_dict(test_IDs_dict) # Creation of the dataframe from the dictionary\n",
    "\n",
    "test_dataF = test_ratings_representation[test_ratings_representation.ratings != 0]\n",
    "#print(test_dataF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "   - Il est normal de mettre un threshold (min_num_ratings) parce qu'on veut un certain nombre de données pour ce prononcer quand à donner une note, ceci implique qu'on enlève des users et des items, du coup notre matrice des ratings va être plus petite. Quand on la remplis et on fait un submit, comment est-ce qu'on gére ça?\n",
    "       - Ici je suppose que c'est bien de faire la selection des ratings pour le train et test --> comme ceci on est pas ou moins biaisé par les movies et users qui n'ont que des 0 et qui donc n'apporte rien apart du \"bruit\"\n",
    "       - Pour le remplissage de ce que l'on doit submit j'ai fait une petite comparaison entre les data que l'on nous donne et ce qui se trouve dans le sample_submission, (enfin je vais le faire) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********** Pre-processing **********\n",
    "min_num_ratings = 10 # or 15 this is based on the information given above\n",
    "ratings_valid = valid_ratings(ratings, num_items_per_user, num_users_per_item,min_num_ratings)\n",
    "train, test = split_data(ratings_valid) # This will put 90% of the items for the users that have at least one non-zero entry and the 10% in test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_application(train ,False ,4,0.01, 20, 0.2, 0.3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********* Try ************\n",
    "#rmse = rmse_movie_mean(train, test)\n",
    "rmse = matrix_factorization_SGD(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done so far\n",
    "- Preview of the data\n",
    "- Pre-processing:\n",
    "    - Choosing only the \"valid ratings\", the users and items that contains more than min_num_ratings\n",
    "    - Splitting the data in test and train, by choosing 90% of the ratings from the valid_ratings and only the non-zeros values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors imported in performance order (best to worst, according to http://surpriselib.com/)\n",
    "from surprise import SVDpp\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import SlopeOne\n",
    "from surprise import BaselineOnly\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import NMF\n",
    "from surprise import CoClustering\n",
    "from surprise import KNNBasic\n",
    "\n",
    "from surprise import KNNWithZScore # not scored --> to be tested quickly\n",
    "\n",
    "\n",
    "\n",
    "from surprise import dataset\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "\n",
    "reader = dataset.Reader(rating_scale=(1, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_surpr=Dataset.load_from_df(dataF[['users ID', 'movies ID', 'ratings']], reader)\n",
    "\n",
    "ratings_surpr.split(n_folds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [SVDpp(),KNNBaseline(),SVD(),SlopeOne(),BaselineOnly(),KNNWithZScore()]\n",
    "perf = {}\n",
    "algo_str = ['SVDpp', 'KNN Baseline','SVD', 'Slope One', 'BaselineOnly', 'KNN with Z score']\n",
    "#perf = np.zeros(len(algos))\n",
    "#i=0\n",
    "for i,algo in enumerate(algos): #for algo in algos:\n",
    "    # Evaluate performances of our algorithm on the dataset.\n",
    "    perf[algo_str[i]] = evaluate(algo, ratings_surpr, measures=['RMSE'])\n",
    "    print_perf(perf[algo_str[i]])\n",
    "#    i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('perf_dictionary.npy', perf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Define: algo, dataset (trainset ##############\n",
    "ratings_ = Dataset.load_from_df(dataF[['users ID', 'movies ID', 'ratings']], reader)\n",
    "trainset = ratings_.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Define: testset ##############\n",
    "test_ratings_ = Dataset.load_from_df(test_dataF[['users ID', 'movies ID', 'ratings']], reader)\n",
    "test_trainset = test_ratings_.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = test_trainset.build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Train and test the algo ###########\n",
    "algorithm = KNNBasic()\n",
    "algorithm.train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = algorithm.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Creation of the lists: row_users, col_movies, estim ########\n",
    "row_users = [] # initialization of the list row_users\n",
    "col_movies = [] # initialization of the list col_movies\n",
    "estim = [] # initialization of the list estim\n",
    "for p in pred: # To loop over the prediction done by the algo on the test set\n",
    "    row_users.append(p.uid) # fill this list with the indices of the users\n",
    "    col_movies.append(p.iid) # fill this list with the indices of the movies\n",
    "    estim.append(p.est) # fill this list with the ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Create the CSV files ##########\n",
    "name = 'try_sub.csv' # Name of the file\n",
    "create_csv_submission(row_users, col_movies, estim, name) # To create the CSV file \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
